\documentclass{report}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amssymb}


\title{Notebook on probability and statistics}
\author{Joaquín Gómez}
\date{}

\newcommand*{\daggerfootnote}[1]{%
  \begingroup
  \renewcommand*{\thefootnote}{\fnsymbol{footnote}}%
  \footnote{#1}%
  \endgroup
}


\newtheorem{example}{$\blacklozenge$ Example}[chapter]
\newtheorem{theorem}{$\blacklozenge$ Theorem}[chapter]
\newtheorem{lemma}{$\blacklozenge$ Lemma}[chapter]
\newtheorem{definition}{$\blacklozenge$ Definition}[chapter]

\begin{document}
\maketitle
\chapter{Counting and series}
We will start this notebook by introducing basic probability concepts.
After that, we will use combinatorics to describe certain experiments.
The subject of combinatorics is essential to calculate probabilities,
and it's useful in many areas of science.
The topics that will be covered are basics and a \textit{must know} in
probability theory and statistics.

Combinatorics requires a basic knowledge of \textit{set theory}. This
document is not focused on set theory, so we will neglect it. However,
it is expected from the reader to know at least some basic notation and
to have a notion of set theory.

\section{Introduction}
The next example will be useful to introduce the notion of ``frequentist probabilities''\daggerfootnote{
    In classical probability theory, probabilities are assumed to exist as axioms; frequentist definitions aim to approximate them empirically.
}. These
rely on the idea that, given $n$ results of an experiment $E$, if the desired result $R$
is present $m$ times after the experiment, then the probability of $R$ is given by
\begin{equation}
    p_R = \frac{m}{n}
\end{equation}

\begin{example}
    If we toss a coin, what is the probability of it getting the first heads in the $n^{th}$ trial?
    This is, the probabilty of the result set to be $R = \left\{T T T \dots T H\right\}$
    (with $n-1$ $T's$)
\end{example}
Given that the coin has 2 sides and assuming a fair coin, we must set the probability of getting
heads as $p_H = \frac{1}{2}$. The probability of tails, $p_T$ is the same.

The probability of the coin to land heads after $n$ throws will be given by
\begin{equation}
    \prod_{k=1}^{n-1}{p_T} \cdot p_H = p_T^{n-1}p_H
\end{equation}
Why? You could ask. Well, think of this: you throw the coin once, you had a $1/2$ chance to get
tails. Now, throwing it again and getting tails \textit{twice} in the same \textit{experiment}
has $1/2$ chance too, but given it's the \textit{same} experiment, you had $1/4$ chance of success,
because to get there you had to succeed the first time. This is a chain of probabilities that
can be drawn as a tree, with each result as a node and connected by a certain \textit{weight} given
by the probability of that result to happen.

This is the first kind of ``probability distribution'' that we will see in this text. One could infer
the value of $p_T$ because, given that we have two possible results
\begin{equation}
    p_H + p_T = 1
\end{equation}
will always be true, because we either have tails or heads after tossing the coin, nothing else. Then
\begin{equation}
    p_T = 1 - p_H
\end{equation}
so we can rewrite (1.2) as
\begin{equation}
    \textit{Geometric PMF} = (1-p)^{n-1}p
\end{equation}
Alright! Now we have introduced a new concept, a PMF. See, its derivation was very simple. However it is
important to know what a PMF is. This will be covered in the \textbf{Discrete Random Variables} chapter.

\section{Counting -- Combinatorics}
We use counting in probabilities to account for the number of possible \textit{orderings} of certain elements,
for example.

\begin{example}
    There are $12$ people in a party. If we want to make groups of $3$, such that we have $4$ groups. How many ways
    of making these groups we have?
\end{example}
This problem ask for the total subsets of $3$ people in a set of $12$ people. The solution is given by the
Binomial Coefficient
\begin{equation}
    \binom{12}{3} = \frac{12!}{3!(12-3)!} = \frac{12!}{4!9!} = 220
\end{equation}

\begin{example}(Deriving the Binomial Coefficient)
    To derive the formula we used in (1.6) we need to first know how to count the total combinations of a set of
    $n$ elements.

    For the first element, we have $n$ options to arrange it, for the second element we have $n-1$ options, as the
    first one is already sorted. For the element in position $n-1$ we just have 2 options, and for the last element,
    we have already determined its position, so it's 1 option only. If we want to count the total ways to arrange
    them, we must multiply the total ways of arranging the first element, by the total ways of arranging the second
    element... and so on.
    \begin{equation}
        \text{total arrangements} = n\cdot(n-1)\cdot(n-2)\cdots 2 \cdot 1 = n!
    \end{equation}
    Now, this formula is meaningful when these $n$ objects are distinct from each other. Now, imagine we want to count
    the number of permutations of $r$ items from these $n$ items.

    We have $n$ ways to choose the first, $n-1$ ways for the second, and in general we have $n-k+1$ ways to choose the $k^{th}$
    item. The total ways of arranging the $k^{th}$ item is given by
    \begin{equation}
        \prod_{j=1}^{k}(n-j+1)
    \end{equation}
    This simplifies as
    \begin{equation}
        \frac{\prod_{j=1}^{n}{(n-j+1)}}{\prod_{j=k+1}^{n}{(n-j+1)}}=\frac{n\cdot(n-1)\cdots2\cdot1}{(n-k)\cdot(n-k-1)\cdots2\cdots1}=\frac{n!}{(n-k)!}
    \end{equation}

    Now, this permutation takes in account that we can sort these $k$ objects in $k!$ ways. Thus, if we want to know how to \textit{choose} the
    objects instead of choosing AND arranging them, we have to divide by $k!$. Thus, we found the Binomial Coefficient
    \begin{equation}
        \binom{n}{k} = \frac{n!}{k!(n-k)!}
    \end{equation}
\end{example}

We have covered a bit of combinatorics. Further topics will be disregarded. However, it is important to at least
have a practical notion of combinations and counting.

\section{Sets and probability}
Sets and probabilities are strongly related. When we measure probabilities, we measure them on sets of particular
objects. For simplicity, these can be numbers, vectors, or any object in a linear space (vector space).

In order to understand probability theory, one must know set theory. The basics at least.
\subsection{Fundamental aspects of set theory}
We will define the fundamental operations for sets, given two sets $A$ and $B$ we have
\begin{list}{$\triangleright$}{1em}
    \item[$\triangleright$] $A$ equals $B$: $A = B = \forall x (x\in A \text{ and } x\in B)$
    \item[$\triangleright$] Union of $A$ and $B$: $A\cup B = \left\{x: x\in A \text{ or } x \in B\right\}$
    \item[$\triangleright$] Intersection of $A$ and $B$: $A\cap B = \left\{x: x\in A \text{ and } x \in B\right\}$
    \item[$\triangleright$] Difference of $A$ and $B$: $A\backslash B = A - B= \left\{x: x\in A \text{ and } x\notin B\right\}$\daggerfootnote{We will use the notation $A\backslash B$}
\end{list}

We introduce a new set $S$. This set contains both $A$ and $B$, this is, for every element $x$ in $A$ or $B$,
$x\in S$. But, there exists $y\in S$ such that $y\notin A\cup B$. We say that $A\subset S$ and $B\subset S$. The
symbol `$\subset$' is called \textit{subset of}. We can also say that $A$ is a subset or is equal to $S$ if $A=S$
or $A \subset S$; we denote this as $A\subseteq S$. We can invert the symbol and say $S\supset A$, or $S \supseteq A$.

\begin{definition}
    Let $A$ and $B$ satisfy $A\cap B \neq \emptyset$\daggerfootnote{The set `$\emptyset$' is called \textit{empty set} and is defined as $\emptyset = \left\{\right\}$. }
    and define $S$ to satisfy $A,B\subset S$. Then we have
    \begin{list}{$\triangleright$}{}
        \item $A^{c} = S\backslash A = \left\{x: x\notin A \text{ and } x\in S\right\}$ (Complement of $A$ in $S$ or absolute complement of $A$)
        \item $A\Delta B = (A\backslash B) \cup (B \backslash A) = \left\{x: x\in A \text{ or } x\in B \text{ and } x \notin A\cap B\right\}$ (Symmetric difference between $A$ and $B$)
    \end{list}
\end{definition}

We will check for these formulas, the first one is trivial \daggerfootnote{the definition of complement needs a frame of reference, otherwise if $A\nsubseteq S$
    we would have $A^{c} = \emptyset$, which means that every element that exists in our space is in $A$.
    For example, if we \textit{restrict} numbers to only be real numbers, then our frame of reference will
    be $\mathbb{R}$, thus, $\mathbb{R}^{c} = \emptyset$ and $\mathbb{N}\subset\mathbb{Z}\subset\mathbb{Q}\subset\mathbb{R}$}.

For the second one, note that if $x\in (A\backslash B)$,
then $x\notin B$. Also, if $x\in (B\backslash A)$, $x\notin A$. Now, let $x\in (A\backslash B)$ and $x\in (B \backslash A)$,
suppose that $x\in A$, so $x\notin B$; but, if $x\in B$, then $x\notin A$. However, let $x\in A\cap B$ so that $x\in A$ and $x\in B$,
consequently, $x\notin A$ and $x\notin B$, which is a contradiction. So $x\notin A\cap B$. Finally, suppose $x\in S\cap (A\cup B)^{c}$,
this also implies $x\notin A$ and $x \notin B$, so $x\notin S\cap(A\cup B)^{c}$. We finally arrive at the conclusion that
either $x\in A$ or $x\in B$, but $x\notin A\cap B$.

\begin{definition}
    The number of subsets of a set $S$ of $n$ elements is given by $2^{n}$
\end{definition}

\begin{proof}
    This definition deserves a proof. Consider the set $S = {s_1, s_2, \dots, s_{n+1}}$. 
    Start by $\emptyset$, which has $0$ elements. The number of subsets of this set is $2^{0} = 1$. 
    Now, for the second subset we select an element $s_1\in S$, we can
    either add it to the empty set or not, so we have $2^{1} = 2$ subsets of $S$. For the second element $s_2 \in S$ we have
    the same situation, we either add it or not, resulting in the subsets $\emptyset, \left\{1\right\}, \left\{1,2\right\}, \left\{2\right\}\subset S$.
    As we continue to add more elements, we reach out to the $n$-th element, suppose that the formula is true 
    and we conjecture that we have $2^{n}$ elements at this time. For the $(n+1)$-th element we have 
    $2^{n+1} = 2^{n}\cdot2$ elements, which is certainly true, since the number of subsets must double: those subsets
    which have $s_{n+1}$ and the same, but without $s_{n+1}$.
\end{proof}

\begin{definition} (Power set)
    The power set of a set $A$ of $n$ elements is a set, denoted by $P(A)$, containing every 
    subset of $A$. This is, $P(A) = \left\{A_i: A_i\subseteq A\right\}$ for $i=1,2\dots,2^{n}$.
\end{definition}

\begin{lemma}
    The set $P(A)$ has $2^{n}$ elements.
\end{lemma}

Later, we will see the use of these definitions on probability theory.

\section{Sample spaces}
\begin{definition}
    A sample space $\Omega$ is the set of \textit{every} possible outcome
    of an experiment.
\end{definition}
We can give some examples of sample spaces.
\begin{example}
    The sample space of and experiment of taking a card from a deck of 50 spanish cards is
    given by $\Omega = \left\{\text{``1 sword''}, \text{``2 sword''}, \dots, \text{``12 gold''}\right\}$.
\end{example}


\end{document}